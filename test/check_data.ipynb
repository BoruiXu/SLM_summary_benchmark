{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kendalltau,pearsonr,spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../../SummEval/model_annotations.aligned.paired.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = data.to_dict(orient='records')\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     tmp = dic[i]['expert_annotations']\n",
    "    \n",
    "#     for j in tmp:\n",
    "#         print(j['relevance'])\n",
    "#     print(\"==================\")\\\n",
    "# print(data.columns)\n",
    "\n",
    "# print(data.iloc[0]['references'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'coherence': 2, 'consistency': 1, 'fluency': 4, 'relevance': 2}, {'coherence': 1, 'consistency': 1, 'fluency': 2, 'relevance': 1}, {'coherence': 1, 'consistency': 1, 'fluency': 3, 'relevance': 2}]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17690612084545437\n"
     ]
    }
   ],
   "source": [
    "# print(data.columns)\n",
    "\n",
    "# print(data.iloc[1][\"text\"])\n",
    "\n",
    "# print(data.iloc[1][\"references\"])\n",
    "\n",
    "#get new dataset\n",
    "#'coherence': 2, 'consistency': 1, 'fluency': 4, 'relevance': 2\n",
    "\n",
    "def get_score(aspect, input_list):\n",
    "    tmp = 0\n",
    "    for i in input_list:\n",
    "        tmp += i[aspect]\n",
    "    return tmp/len(input_list)\n",
    "\n",
    "def get_score_list(aspect, input_list):\n",
    "    tmp = []\n",
    "    for i in input_list:\n",
    "        tmp.append(i[aspect])\n",
    "    return tmp\n",
    "\n",
    "\n",
    "dic = data.to_dict(orient='records')\n",
    "\n",
    "model = (data[\"model_id\"].unique()).tolist()\n",
    "\n",
    "\n",
    "result = []\n",
    "\n",
    "result_list_a = []\n",
    "result_list_b = []\n",
    "\n",
    "e= []\n",
    "for m in model:\n",
    "    dic = data[data[\"model_id\"] == m].to_dict(orient='records')\n",
    "    \n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    d = []\n",
    "    \n",
    "    for i in range(len(dic)):\n",
    "        \n",
    "        tmp_list = get_score_list(\"relevance\",dic[i][\"expert_annotations\"])\n",
    "        a.append(float(tmp_list[0]))\n",
    "        b.append(float(tmp_list[1]))\n",
    "        c.append(float(tmp_list[2]))\n",
    "        d.append(float((tmp_list[0]+tmp_list[1]+tmp_list[2]))/3)\n",
    "    e.append(kendalltau(a, c))\n",
    "    # print(f\"model:{m}, kendalltau correlation a b {kendalltau(a, b)}\")\n",
    "    result_list_a.append(float(np.mean(a)))\n",
    "    result_list_b.append(float(np.mean(b)))\n",
    "     \n",
    "    \n",
    "\n",
    "print(np.mean(e))\n",
    "# print(\"kendalltau correlation a b \",kendalltau(a, b))\n",
    "# print(\"kendalltau correlation a c \",kendalltau(a, c))\n",
    "# print(\"kendalltau correlation b c \",kendalltau(b, c))\n",
    "# print(\"system level kendalltau correlation a b \",kendalltau(result_list_a, result_list_b))\n",
    "\n",
    "# print(\"----------------------------------------------\")\n",
    "# #pearsonr\n",
    "# print(\"pearsonr correlation a b \",pearsonr(a, b))\n",
    "# print(\"pearsonr correlation a c \",pearsonr(a, c))\n",
    "# print(\"pearsonr correlation b c \",pearsonr(b, c))\n",
    "# print(\"pearsonr correlation a d \",pearsonr(result_list_a, result_list_d))\n",
    "\n",
    "# print(\"spearmanr correlation a d \",spearmanr(result_list_a, result_list_d))\n",
    "\n",
    "# print(a)\n",
    "# print(d)\n",
    "\n",
    "#save filter data\n",
    "\n",
    "# for i in range(len(dic)):\n",
    "#     tmp_dic = {}\n",
    "#     tmp_dic[\"article\"] = dic[i][\"text\"]\n",
    "#     tmp_dic[\"summary\"] = dic[i][\"decoded\"]\n",
    "#     tmp_dic[\"model\"] = dic[i][\"model_id\"]\n",
    "    \n",
    "#     tmp_dic[\"expert_coherence\"] = get_score(\"coherence\",dic[i][\"expert_annotations\"])\n",
    "#     tmp_dic[\"expert_relevance\"] = get_score(\"relevance\",dic[i][\"expert_annotations\"])\n",
    "#     tmp_dic[\"expert_consistency\"] = get_score(\"consistency\",dic[i][\"expert_annotations\"])\n",
    "#     tmp_dic[\"expert_fluency\"] = get_score(\"fluency\",dic[i][\"expert_annotations\"])\n",
    "    \n",
    "#     tmp_dic[\"turker_coherence\"] = get_score(\"coherence\",dic[i][\"turker_annotations\"])\n",
    "#     tmp_dic[\"turker_relevance\"] = get_score(\"relevance\",dic[i][\"turker_annotations\"])\n",
    "#     tmp_dic[\"turker_consistency\"] = get_score(\"consistency\",dic[i][\"turker_annotations\"])\n",
    "#     tmp_dic[\"turker_fluency\"] = get_score(\"fluency\",dic[i][\"turker_annotations\"])\n",
    "    \n",
    "#     tmp_dic[\"all_coherence\"] = (tmp_dic[\"expert_coherence\"] + tmp_dic[\"turker_coherence\"])/2\n",
    "#     tmp_dic[\"all_relevance\"] = (tmp_dic[\"expert_relevance\"] + tmp_dic[\"turker_relevance\"])/2\n",
    "#     tmp_dic[\"all_consistency\"] = (tmp_dic[\"expert_consistency\"] + tmp_dic[\"turker_consistency\"])/2\n",
    "#     tmp_dic[\"all_fluency\"] = (tmp_dic[\"expert_fluency\"] + tmp_dic[\"turker_fluency\"])/2\n",
    "    \n",
    "#     tmp_dic[\"references\"] = dic[i][\"references\"]\n",
    "    \n",
    "#     result.append(tmp_dic)\n",
    "\n",
    "# save to json\n",
    "# with open('filter_annotations_summeval_reference.jsonl', 'w') as outfile:\n",
    "#     json.dump(result, outfile, indent=4)\n",
    "# print(\"done\")    \n",
    "# print(kendalltau([1,2,3,4,5],[2,3,4,5,4])) \n",
    "# print(pearsonr([1,2,3,4,5],[10,20,30,40,50]))\n",
    "#    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: M1, correlation is 0.076170496183279\n",
      "model: M10, correlation is 0.3556297482749319\n",
      "model: M11, correlation is 0.2144162046241208\n",
      "model: M12, correlation is 0.28375927905638604\n",
      "model: M13, correlation is 0.20940729986744303\n",
      "model: M14, correlation is 0.1635804730107665\n",
      "model: M15, correlation is 0.2570859901533514\n",
      "model: M17, correlation is 0.19680235028326123\n",
      "model: M2, correlation is 0.37970433642009155\n",
      "model: M20, correlation is 0.008152220895776444\n",
      "model: M22, correlation is 0.23832531156444012\n",
      "model: M23, correlation is 0.15337762520189516\n",
      "model: M5, correlation is 0.30296528095523045\n",
      "model: M8, correlation is 0.2128133597387542\n",
      "model: M9, correlation is 0.17691724289025548\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def correlation_score(dict1, dict2):\n",
    "    #system level\n",
    "    tmp_list1 = []\n",
    "    tmp_list2 = []\n",
    "    for i in dict1.keys():\n",
    "        tmp_list1.append(np.mean(dict1[i]))\n",
    "        tmp_list2.append(np.mean(dict2[i]))\n",
    "    print(\"correlation of system level is \", spearmanr(tmp_list1, tmp_list2)[0])\n",
    "    \n",
    "    #summary level\n",
    "    # total_corr = 0\n",
    "    \n",
    "    # for i in dict1.keys():\n",
    "    #     total_corr+=spearmanr(dict1[i], dict2[i])[0]\n",
    "    # print(\"correlation of summary level is \", total_corr/len(dict1.keys()))\n",
    "    \n",
    "\n",
    "def correlation_score_per_system(list1, list2,keys):\n",
    "    r = kendalltau(list1, list2)[0]\n",
    "    print(f\"model: {keys}, correlation is {r}\")\n",
    "    \n",
    "\n",
    "dict1 = json.load(open('./LLM_evaluation_correlation_with_human/Rouge/human_score_filter_annotations_summeval_expert_coherence_eva.json'))\n",
    "\n",
    "dict2 = json.load(open('./LLM_evaluation_correlation_with_human/Rouge/rouge1_filter_annotations_summeval_expert_relevance_eva.json'))\n",
    "\n",
    "# correlation_score(dict1, dict2)\n",
    "\n",
    "for i in dict1.keys():\n",
    "    correlation_score_per_system(dict1[i], dict2[i],i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['article_id', 'article', 'summary'], dtype='object')\n",
      "Neil Lennon is succeeding Alan Stubbs at Hibernian. The former Celtic manager is looking to add to his list of achievements, as well as find stability amidst an ever-changing game. The move was said to be mutually beneficial, as players have a tendency to perform well under his guidance.\n"
     ]
    }
   ],
   "source": [
    "#check data in benchmark LLM human writer\n",
    "\n",
    "data = pd.read_json('../../benchmark_llm_summarization/filtered_df.json')\n",
    "print(data.columns)\n",
    "\n",
    "data['summary'] = data['summary'].str.strip()\n",
    "\n",
    "print(data.iloc[0][\"summary\"])\n",
    "\n",
    "data = data.to_dict(orient='records')\n",
    "#save\n",
    "import json\n",
    "json_file = 'filtered_df_strip.json'\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Dec 02 2020\n",
      "1        Dec 02 2020\n",
      "2        Dec 02 2020\n",
      "3        Dec 02 2020\n",
      "4        Dec 02 2020\n",
      "            ...     \n",
      "26752    Feb 13 2019\n",
      "26753    Feb 13 2019\n",
      "26754    Feb 13 2019\n",
      "26755    Feb 13 2019\n",
      "26756    Feb 13 2019\n",
      "Name: 1, Length: 26757, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#查看路透特新闻数据集\n",
    "\n",
    "news = pd.read_csv('/home/xbr/LLM/dataset/Reuters_news.csv',header=None)\n",
    "\n",
    "news[1] = news[1].str.replace(\"\\n\",\"\") \n",
    "print(news[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xbr/anaconda3/envs/LLM/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for chiseng-cheang/TempoSum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/chiseng-cheang/TempoSum\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    }
   ],
   "source": [
    "#try TempoSum dataset\n",
    "import datasets\n",
    "dataset = datasets.load_dataset('chiseng-cheang/TempoSum', 'BBC_future')\n",
    "\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kendalltau correlation of system level is  0.7044161301655284\n",
      "spearmans correlation of system level is  0.8660142784299882\n",
      "kendalltau correlation of summary level is  nan\n",
      "spearmans correlation of summary level is  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1789888/2066288017.py:21: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  total_corr2+=spearmanr(dict1[i], dict2[i])[0]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kendalltau, spearmanr\n",
    "import json\n",
    "import numpy as np\n",
    "def correlation_score(dict1, dict2):\n",
    "    #system level\n",
    "    tmp_list1 = []\n",
    "    tmp_list2 = []\n",
    "    for i in dict1.keys():\n",
    "        tmp_list1.append(np.mean(dict1[i]))\n",
    "        tmp_list2.append(np.mean(dict2[i]))\n",
    "        \n",
    "    print(\"kendalltau correlation of system level is \", kendalltau(tmp_list1, tmp_list2)[0])\n",
    "    print(\"spearmans correlation of system level is \", spearmanr(tmp_list1, tmp_list2)[0])\n",
    "    \n",
    "    #summary level\n",
    "    total_corr = 0\n",
    "    total_corr2 = 0\n",
    "    \n",
    "    for i in dict1.keys():\n",
    "        total_corr+=kendalltau(dict1[i], dict2[i])[0]\n",
    "        total_corr2+=spearmanr(dict1[i], dict2[i])[0]\n",
    "    print(\"kendalltau correlation of summary level is \", total_corr/len(dict1.keys()))\n",
    "    print(\"spearmans correlation of summary level is \", total_corr2/len(dict1.keys()))\n",
    "    \n",
    "d1 = json.load(open('./LLM_evaluation_correlation_with_human/qwen/Qwen1.5-72B-Chat_likert_evaluation_results_cnndm_average_relevance_eva.json'))\n",
    "d2 = json.load(open('./LLM_evaluation_correlation_with_human/qwen/human_score_likert_evaluation_results_cnndm_average_relevance_eva.json'))\n",
    "\n",
    "correlation_score(d1,d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 19:34:27.435765: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-02 19:34:27.482493: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 19:34:28.298337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/xbr/anaconda3/envs/LLM/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [1.0, 1.0], 'recall': [1.0, 1.0], 'f1': [1.0, 1.0], 'hashcode': 'microsoft/deberta-xlarge-mnli_L40_no-idf_version=0.3.12(hug_trans=4.38.1)'}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"microsoft/deberta-xlarge-mnli\",lang=\"en\")\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"microsoft/deberta-xlarge-mnli\",lang=\"en\")\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"microsoft/deberta-xlarge-mnli\",lang=\"en\")\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"microsoft/deberta-xlarge-mnli\",lang=\"en\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xbr/anaconda3/envs/LLM/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "factkb_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", padding=\"max_length\", truncation=True)\n",
    "factkb_model = AutoModelForSequenceClassification.from_pretrained(\"bunsenfeng/FactKB\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是否只包含一个单数字: 5 asdasdas False\n",
      "是否只包含一个单数字: 10 False\n",
      "是否只包含一个单数字: a False\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# t1 = \"1112123123\"\n",
    "# t2 = \"213214234234\"\n",
    "# input_factkb = [[t1, t2]]\n",
    "# factkb_tokens = factkb_tokenizer(input_factkb, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(factkb_model.device)\n",
    "# factkb_logits = factkb_model(**factkb_tokens).logits\n",
    "# factkb_res = torch.softmax(factkb_logits, dim=1)\n",
    "# print(factkb_res)\n",
    "\n",
    "import re\n",
    "\n",
    "def is_single_digit_string(text):\n",
    "    # 使用正则表达式匹配字符串是否只包含一个单数字\n",
    "    match = re.match(r'^\\d$', text)\n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# 测试字符串\n",
    "text1 = \"5 asdasdas\"\n",
    "text2 = \"10\"\n",
    "text3 = \"a\"\n",
    "\n",
    "# 检查字符串是否只包含一个单数字\n",
    "print(\"是否只包含一个单数字:\", text1, is_single_digit_string(text1))\n",
    "print(\"是否只包含一个单数字:\", text2, is_single_digit_string(text2))\n",
    "print(\"是否只包含一个单数字:\", text3, is_single_digit_string(text3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458.7\n"
     ]
    }
   ],
   "source": [
    "#average length\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data =pd.read_json('./data/likert_evaluation_results_cnndm_average_with_qwen.json')\n",
    "\n",
    "data = data[data['model']=='reference']['article']\n",
    "\n",
    "n = len(data)\n",
    "\n",
    "l = 0\n",
    "for i in data:\n",
    "    t = i.split(' ')\n",
    "    l+=len(t)\n",
    "    \n",
    "print(l/n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santiago Sánchez, right, and a friend walk in Iraq's Kurdistan region in August\n",
      "\n",
      "Iran's embassy in Spain says it has released Santiago Sánchez: a Spanish football fan detained during a trek from Madrid to Qatar for the men's 2022 football World Cup, and held in Tehran.\n",
      "\n",
      "In a statement on X, the Iranian embassy said Mr Sánchez's release came thanks to the two countries' \"friendly and historical relations\".\n",
      "\n",
      "All contact from Mr Sánchez was lost as he neared the final leg of his trip.\n",
      "\n",
      "He was detained after visiting Mahsa Amini's grave, Spanish media report.\n",
      "\n",
      "Ms Amini died in custody after being arrested by morality police in Tehran for allegedly wearing her hijab \"improperly\".\n",
      "\n",
      "Her death sparked a wave of protests in Iran and beyond in 2022 - and many Iranians continue to defy a deadly crackdown by security forces.\n",
      "\n",
      "Prior to Mr Sánchez's disappearance in October 2022, he shared each leg of his mammoth journey on social media.\n",
      "\n",
      "A former paratrooper and passionate Real Madrid fan, he began the trip in January 2022, travelling across Europe, Turkey and Iraq - before being held in Iran for more than a year.\n",
      "\n",
      "In a post on social media the day before he went silent, Mr Sánchez shared a series of photos with the caption: \"Last village in northern Iraq, a mountain separates me from reaching Iran, the next country before reaching Qatar\".\n",
      "\n",
      "At the time of Mr Sánchez's detention, his friend Francho Salamanca told the BBC: \"He has been arrested and he is now in a Tehran prison\".\n",
      "\n",
      "He said his friend had been upbeat about travelling through Iran, and had done a similar journey to get to Saudi Arabia in 2019.\n",
      "\n",
      "Mr Sánchez began - and then postponed - a hunger strike in detention in September, Spain's ABC broadcaster reported. Relatives were quoted saying he postponed the protest after the prison director said he could see a doctor for his toothaches.\n",
      "\n",
      "News of his whereabouts came after weeks of mounting concern from his family and friends.\n",
      "\n",
      "In the same statement on social media, the Iranian embassy in Spain said Mr Sánchez was the only Spanish national held in Iran.\n",
      "\n",
      "Ana Baneira Suarez, a Spanish activist who worked for a human rights NGO, was arrested in Tehran in November 2022 - but released the following February.\n",
      "\n",
      "Mr Sánchez started his trip in January, travelling across Europe, Turkey and Iraq\n",
      "• None Fan detained in Iran while hiking to World Cup\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "data = json.load(open('/home/xbr/LLM/summary_benchmark/dataset/sample_dataset/bbc2024_sample_0k5_1k5.json'))\n",
    "\n",
    "print(data[0]['article'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
