{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoModelForSeq2SeqLM\n",
    "# from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "# from transformers import AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "#load bert score model\n",
    "from evaluate import load\n",
    "bert_score = load(\"bertscore\")\n",
    "\n",
    "\n",
    "def rouge(refs, preds):\n",
    "    \"\"\"\n",
    "    Returns `t5` style ROUGE scores. See the related implementation:\n",
    "    https://github.com/google-research/text-to-text-transfer-transformer/blob/3d10afd51ba97ac29eb66ae701eca274488202f7/t5/evaluation/metrics.py#L68\n",
    "    :param refs:\n",
    "        A `list` of reference `strs`.\n",
    "    :param preds:\n",
    "        A `list` of predicted `strs`.\n",
    "    \"\"\"\n",
    "    rouge_types = [\"rouge1\", \"rouge2\", \"rougeLsum\"]\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_types)\n",
    "    # Add newlines between sentences to correctly compute `rougeLsum`.\n",
    "\n",
    "    def _prepare_summary(summary):\n",
    "        summary = summary.replace(\" . \", \".\\n\")\n",
    "        return summary\n",
    "\n",
    "    # Accumulate confidence intervals.\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "    for ref, pred in zip(refs, preds):\n",
    "        ref = _prepare_summary(ref)\n",
    "        pred = _prepare_summary(pred)\n",
    "        aggregator.add_scores(scorer.score(ref, pred))\n",
    "    result = aggregator.aggregate()\n",
    "    \n",
    "    return {type: result[type].mid.fmeasure  for type in rouge_types}\n",
    "\n",
    "\n",
    "def BertScore(refs, preds):\n",
    "    bert_score_res = bert_score.compute(predictions=[refs], references=[preds], model_type=\"microsoft/deberta-xlarge-mnli\", lang=\"en\")\n",
    "    \n",
    "    return bert_score_res\n",
    "\n",
    "def get_score(refs, preds, acticles):\n",
    "    rouge_res = rouge([refs], [preds])\n",
    "    \n",
    "    bert_score_res = BertScore(refs, preds)\n",
    "    \n",
    "    total_res = {\n",
    "            \"rouge1\": rouge_res[\"rouge1\"],\n",
    "            \"rougeL\": rouge_res[\"rougeLsum\"],\n",
    "            \"bertscore_f1\": float(bert_score_res[\"f1\"][0])\n",
    "        }\n",
    "    \n",
    "    return total_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nick Scholfield is l\n",
      "Nick Scholfield is l\n",
      "Nick Scholfield is l\n",
      "Dr Mehmet Oz's fello\n",
      "Dr Mehmet Oz's fello\n",
      "\"It's all about taki\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/xbr/LLM/summary_benchmark/test/compute_rouge.ipynb 单元格 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a227862725f613130305f325f4e5553227d/home/xbr/LLM/summary_benchmark/test/compute_rouge.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m news \u001b[39m=\u001b[39m writer[i][\u001b[39m'\u001b[39m\u001b[39marticle\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m20\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a227862725f613130305f325f4e5553227d/home/xbr/LLM/summary_benchmark/test/compute_rouge.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(news)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a227862725f613130305f325f4e5553227d/home/xbr/LLM/summary_benchmark/test/compute_rouge.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m l \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39;49mindex[reference[\u001b[39m'\u001b[39;49m\u001b[39marticle\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mcontains(news)][\u001b[39m0\u001b[39;49m]\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.11/site-packages/pandas/core/indexes/base.py:5385\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5382\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mor\u001b[39;00m is_float(key):\n\u001b[1;32m   5383\u001b[0m     \u001b[39m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[1;32m   5384\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mcast_scalar_indexer(key)\n\u001b[0;32m-> 5385\u001b[0m     \u001b[39mreturn\u001b[39;00m getitem(key)\n\u001b[1;32m   5387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[1;32m   5388\u001b[0m     \u001b[39m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[1;32m   5389\u001b[0m     \u001b[39m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[1;32m   5390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_slice(key)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "data = pd.read_json(\"/home/xbr/LLM/benchmark_llm_summarization/likert_evaluation_results.json\")\n",
    "\n",
    "reference = data[data['model']==\"reference\"].drop_duplicates(subset=['article'])\n",
    "\n",
    "davinci_0shot = data[data['model']==\"openai_text-davinci-002 (0 shot)\"].drop_duplicates(subset=['article'])\n",
    "\n",
    "\n",
    "\n",
    "writer = pd.read_json(\"/home/xbr/LLM/benchmark_llm_summarization/writer_summaries.json\").to_dict(orient='records')\n",
    "\n",
    "for i in range(len(writer)):\n",
    "    news = writer[i]['article'][:20]\n",
    "    print(news)\n",
    "    l = reference.index[reference['article'].str.contains(news)][0]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
