{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate evey tiny LLM model on news summarization\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_eval --model hf --model_args pretrained=google/gemma-1.1-2b-it,trust_remote_code=True --tasks cnndm_qwen --device cuda:3 --batch_size auto --num_fewshot 0 --log_samples --output_path ./test_gemma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
