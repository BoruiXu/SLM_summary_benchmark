{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#corr\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index for LLM model\n",
    "\n",
    "# 1\tphi-2\n",
    "# 2\tinternLM2-1.8b\n",
    "# 3\tinternLM2-1.8b-chat\n",
    "# 4\tmistral_7b\n",
    "# 5\tmistral_7b_insturct0.2\n",
    "# 6\tTinyLlama-1.1-chat-1.0\n",
    "# 7\tminicpm-2b-sft-bf16\n",
    "# 8\tgemma-1.1-2b\n",
    "# 9\tbloom-560m\n",
    "# 10\tqwen1.5-0.5b-chat\n",
    "# 11\tqwen1.5-1.8b-chat\n",
    "# 12\tLitelama-460M\n",
    "# 13\tgpt-neo-1.3b\n",
    "# 14\tphi-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3186813186813187\n",
      "[3, 5, 6, 10, 2, 4, 8, 14, 11, 13, 7, 12, 9, 1]\n",
      "[3, 6, 7, 10, 1, 5, 8, 14, 11, 12, 4, 13, 9, 2]\n",
      "0.8901098901098902\n"
     ]
    }
   ],
   "source": [
    "#convert to fixed position rank\n",
    "def rank_convert(list1):\n",
    "    size = len(list1)\n",
    "    list2 = []\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if list1[j] == (i+1):\n",
    "                list2.append(j+1)\n",
    "    return list2\n",
    "\n",
    "\n",
    "#Xsum bert soce rank high to low\n",
    "xsum_bertscore = [14,5,1,6,2,3,11,7,13,4,9,12,10,8]\n",
    "newsroom_bertscore = [14,5,1,6,2,3,11,7,4,13,9,12,10,8]\n",
    "xsum_relevance_qwen72b = [5,14,1,11,6,2,3,7,13,4,9,10,12,8]\n",
    "xsum_coherence_qwen72b = [5,14,1,11,2,6,3,7,13,4,9,10,12,8]\n",
    "\n",
    "\n",
    "\n",
    "print(kendalltau(xsum_bertscore,xsum_relevance_qwen72b)[0])\n",
    "\n",
    "print(rank_convert(xsum_bertscore))\n",
    "print(rank_convert(xsum_relevance_qwen72b))\n",
    "\n",
    "print(kendalltau(rank_convert(xsum_bertscore),rank_convert(xsum_relevance_qwen72b))[0])\n",
    "\n",
    "# print(kendalltau(xsum_bertscore,newsroom_bertscore)[0])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
